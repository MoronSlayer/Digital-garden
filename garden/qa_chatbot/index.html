<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Mulish:wght@300;400;600;700;800&family=Frank+Ruhl+Libre:wght@200;300;400;500;600&family=Encode+Sans+Semi+Condensed:wght@400&display=swap" rel=stylesheet><link rel=stylesheet type=text/css href=/Digital-garden/css/bootstrap.min.css><link rel=stylesheet type=text/css href=/Digital-garden/css/all.min.css><link disabled id=dark-mode-theme rel=stylesheet href=/Digital-garden/css/dark.css><link rel=stylesheet type=text/css href=/Digital-garden/css/style.css><link rel=stylesheet type=text/css href=/Digital-garden/css/my_style.css><title>My Digital Garden | Q&amp;A chatbot with OpenAI Langchain and ChromaDB</title><meta name=description content="quick notes on dev iterations"></head><body><nav class="navbar navbar-expand-lg navbar-light bg-light"><div class=container><a class=navbar-brand href=https://ritesh1137.github.io/Digital-garden/><b style=font-weight:800>RP</b></a>
<button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarNavDropdown aria-controls=navbarNavDropdown aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarNavDropdown><ul class="navbar-nav ms-auto mt-2 mt-lg-0"><li class=nav-item><a class=nav-link href=/Digital-garden/garden/>Digital Garden</a></li><li class=nav-item><a class=nav-link href=/Digital-garden/projects/>Projects</a></li><li class=nav-item><a class=nav-link href=/Digital-garden/library/>Library</a></li><li class=nav-item><a class=nav-link href=/Digital-garden/about/>About</a></li><li class="nav-item px-2 pt-1"><a class="btn fas fa-moon" id=dark-mode-toggle></a></li></ul></div></div></nav><div id=content><div class=container style=max-width:800px><div class="py-4 rounded-3"><div class="container-fluid py-2"><h1 class="display-2 mb-4 text-center">Q&amp;A chatbot with OpenAI Langchain and ChromaDB</h1></div><p class="text-center fs-4 fst-italic serif">quick notes on dev iterations</p><div class="text-center pt-4"></div></div><div class="row justify-content-center mb-5"><div class=col-12><p class="card-date m-0">Created Feb 16, 2024 -
Last updated: Feb 16, 2024</p><hr class=dropdown-divider><div class="row justify-content-between"><div class=col-sm-4><span class=status>Seeding ðŸŒ±</span></div><div class=col-sm-8 style=text-align:right><span onclick='handleTagClick("large-language-models","garden")' class="badge tag-badge">large-language-models</span></div></div></div></div><div class="container-fluid py-2"><div class="serif main-content"><p>A baisc version of a Q&amp;A chatbot using Chroma DB as the vector database and the OpenAI api is shown below:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>!</span><span style=color:#111>pip</span> <span style=color:#f92672>-</span><span style=color:#111>q</span> <span style=color:#111>install</span> <span style=color:#111>langchain</span> <span style=color:#111>openai</span> <span style=color:#111>tiktoken</span> <span style=color:#111>chromadb</span> 
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>!</span><span style=color:#111>wget</span> <span style=color:#f92672>-</span><span style=color:#111>q</span> <span style=color:#111>https</span><span style=color:#111>:</span><span style=color:#f92672>//</span><span style=color:#111>www</span><span style=color:#f92672>.</span><span style=color:#111>dropbox</span><span style=color:#f92672>.</span><span style=color:#111>com</span><span style=color:#f92672>/</span><span style=color:#111>s</span><span style=color:#f92672>/</span><span style=color:#111>vs6ocyvpzzncvwh</span><span style=color:#f92672>/</span><span style=color:#111>new_articles</span><span style=color:#f92672>.</span><span style=color:#111>zip</span>
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>!</span><span style=color:#111>unzip</span> <span style=color:#f92672>-</span><span style=color:#111>q</span> <span style=color:#111>new_articles</span><span style=color:#f92672>.</span><span style=color:#111>zip</span> <span style=color:#f92672>-</span><span style=color:#111>d</span> <span style=color:#111>new_articles</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>os</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>os</span><span style=color:#f92672>.</span><span style=color:#111>environ</span><span style=color:#111>[</span><span style=color:#d88200>&#34;OPENAI_API_KEY&#34;</span><span style=color:#111>]</span> <span style=color:#f92672>=</span> <span style=color:#d88200>&#34;YOUR_KEY&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.vectorstores</span> <span style=color:#f92672>import</span> <span style=color:#111>Chroma</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.embeddings</span> <span style=color:#f92672>import</span> <span style=color:#111>OpenAIEmbeddings</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.text_splitter</span> <span style=color:#f92672>import</span> <span style=color:#111>RecursiveCharacterTextSplitter</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.llms</span> <span style=color:#f92672>import</span> <span style=color:#111>OpenAI</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.chains</span> <span style=color:#f92672>import</span> <span style=color:#111>RetrievalQA</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.document_loaders</span> <span style=color:#f92672>import</span> <span style=color:#111>TextLoader</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.document_loaders</span> <span style=color:#f92672>import</span> <span style=color:#111>DirectoryLoader</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>loader</span> <span style=color:#f92672>=</span> <span style=color:#111>DirectoryLoader</span><span style=color:#111>(</span><span style=color:#d88200>&#39;./new_articles/&#39;</span><span style=color:#111>,</span> <span style=color:#111>glob</span><span style=color:#f92672>=</span><span style=color:#d88200>&#34;./*.txt&#34;</span><span style=color:#111>,</span> <span style=color:#111>loader_cls</span><span style=color:#f92672>=</span><span style=color:#111>TextLoader</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>documents</span> <span style=color:#f92672>=</span> <span style=color:#111>loader</span><span style=color:#f92672>.</span><span style=color:#111>load</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span><span style=color:#111>text_splitter</span> <span style=color:#f92672>=</span> <span style=color:#111>RecursiveCharacterTextSplitter</span><span style=color:#111>(</span><span style=color:#111>chunk_size</span><span style=color:#f92672>=</span><span style=color:#ae81ff>1000</span><span style=color:#111>,</span> <span style=color:#111>chunk_overlap</span><span style=color:#f92672>=</span><span style=color:#ae81ff>200</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>texts</span> <span style=color:#f92672>=</span> <span style=color:#111>text_splitter</span><span style=color:#f92672>.</span><span style=color:#111>split_documents</span><span style=color:#111>(</span><span style=color:#111>documents</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>persist_directory</span> <span style=color:#f92672>=</span> <span style=color:#d88200>&#39;db&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>embedding</span> <span style=color:#f92672>=</span> <span style=color:#111>OpenAIEmbeddings</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>vectordb</span> <span style=color:#f92672>=</span> <span style=color:#111>Chroma</span><span style=color:#f92672>.</span><span style=color:#111>from_documents</span><span style=color:#111>(</span><span style=color:#111>documents</span><span style=color:#f92672>=</span><span style=color:#111>texts</span><span style=color:#111>,</span> 
</span></span><span style=display:flex><span>                                 <span style=color:#111>embedding</span><span style=color:#f92672>=</span><span style=color:#111>embedding</span><span style=color:#111>,</span>
</span></span><span style=display:flex><span>                                 <span style=color:#111>persist_directory</span><span style=color:#f92672>=</span><span style=color:#111>persist_directory</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>vectordb</span><span style=color:#f92672>.</span><span style=color:#111>persist</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span><span style=color:#111>vectordb</span> <span style=color:#f92672>=</span> <span style=color:#00a8c8>None</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>vectordb</span> <span style=color:#f92672>=</span> <span style=color:#111>Chroma</span><span style=color:#111>(</span><span style=color:#111>persist_directory</span><span style=color:#f92672>=</span><span style=color:#111>persist_directory</span><span style=color:#111>,</span> 
</span></span><span style=display:flex><span>                  <span style=color:#111>embedding_function</span><span style=color:#f92672>=</span><span style=color:#111>embedding</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>retriever</span> <span style=color:#f92672>=</span> <span style=color:#111>vectordb</span><span style=color:#f92672>.</span><span style=color:#111>as_retriever</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>docs</span> <span style=color:#f92672>=</span> <span style=color:#111>retriever</span><span style=color:#f92672>.</span><span style=color:#111>get_relevant_documents</span><span style=color:#111>(</span><span style=color:#d88200>&#34;How much money did Pando raise?&#34;</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>retriever</span> <span style=color:#f92672>=</span> <span style=color:#111>vectordb</span><span style=color:#f92672>.</span><span style=color:#111>as_retriever</span><span style=color:#111>(</span><span style=color:#111>search_kwargs</span><span style=color:#f92672>=</span><span style=color:#111>{</span><span style=color:#d88200>&#34;k&#34;</span><span style=color:#111>:</span> <span style=color:#ae81ff>2</span><span style=color:#111>})</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>qa_chain</span> <span style=color:#f92672>=</span> <span style=color:#111>RetrievalQA</span><span style=color:#f92672>.</span><span style=color:#111>from_chain_type</span><span style=color:#111>(</span><span style=color:#111>llm</span><span style=color:#f92672>=</span><span style=color:#111>OpenAI</span><span style=color:#111>(),</span> 
</span></span><span style=display:flex><span>                                  <span style=color:#111>chain_type</span><span style=color:#f92672>=</span><span style=color:#d88200>&#34;stuff&#34;</span><span style=color:#111>,</span> 
</span></span><span style=display:flex><span>                                  <span style=color:#111>retriever</span><span style=color:#f92672>=</span><span style=color:#111>retriever</span><span style=color:#111>,</span> 
</span></span><span style=display:flex><span>                                  <span style=color:#111>return_source_documents</span><span style=color:#f92672>=</span><span style=color:#00a8c8>True</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#d88200>&#39;&#39;&#39;
</span></span></span><span style=display:flex><span><span style=color:#d88200>function to cite sources
</span></span></span><span style=display:flex><span><span style=color:#d88200>&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span><span style=color:#00a8c8>def</span> <span style=color:#75af00>process_llm_response</span><span style=color:#111>(</span><span style=color:#111>llm_response</span><span style=color:#111>):</span>
</span></span><span style=display:flex><span>    <span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>llm_response</span><span style=color:#111>[</span><span style=color:#d88200>&#39;result&#39;</span><span style=color:#111>])</span>
</span></span><span style=display:flex><span>    <span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#d88200>&#39;</span><span style=color:#8045ff>\n\n</span><span style=color:#d88200>Sources:&#39;</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>for</span> <span style=color:#111>source</span> <span style=color:#f92672>in</span> <span style=color:#111>llm_response</span><span style=color:#111>[</span><span style=color:#d88200>&#34;source_documents&#34;</span><span style=color:#111>]:</span>
</span></span><span style=display:flex><span>        <span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>source</span><span style=color:#f92672>.</span><span style=color:#111>metadata</span><span style=color:#111>[</span><span style=color:#d88200>&#39;source&#39;</span><span style=color:#111>])</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># some examples:</span>
</span></span><span style=display:flex><span><span style=color:#111>query</span> <span style=color:#f92672>=</span> <span style=color:#d88200>&#34;How much money did Pando raise?&#34;</span>
</span></span><span style=display:flex><span><span style=color:#111>llm_response</span> <span style=color:#f92672>=</span> <span style=color:#111>qa_chain</span><span style=color:#111>(</span><span style=color:#111>query</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>process_llm_response</span><span style=color:#111>(</span><span style=color:#111>llm_response</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>query</span> <span style=color:#f92672>=</span> <span style=color:#d88200>&#34;What is generative ai?&#34;</span>
</span></span><span style=display:flex><span><span style=color:#111>llm_response</span> <span style=color:#f92672>=</span> <span style=color:#111>qa_chain</span><span style=color:#111>(</span><span style=color:#111>query</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>process_llm_response</span><span style=color:#111>(</span><span style=color:#111>llm_response</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#d88200>&#39;&#39;&#39;
</span></span></span><span style=display:flex><span><span style=color:#d88200>Now to use the vector DB as without having to recreate the emdeddings for documents,
</span></span></span><span style=display:flex><span><span style=color:#d88200>we can use the below code
</span></span></span><span style=display:flex><span><span style=color:#d88200>&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>!</span><span style=color:#111>zip</span> <span style=color:#f92672>-</span><span style=color:#111>r</span> <span style=color:#111>db</span><span style=color:#f92672>.</span><span style=color:#111>zip</span> <span style=color:#f92672>./</span><span style=color:#111>db</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># To cleanup, you can delete the collection</span>
</span></span><span style=display:flex><span><span style=color:#111>vectordb</span><span style=color:#f92672>.</span><span style=color:#111>delete_collection</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span><span style=color:#111>vectordb</span><span style=color:#f92672>.</span><span style=color:#111>persist</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># delete the directory</span>
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>!</span><span style=color:#111>rm</span> <span style=color:#f92672>-</span><span style=color:#111>rf</span> <span style=color:#111>db</span><span style=color:#f92672>/</span>
</span></span><span style=display:flex><span><span style=color:#d88200>&#39;&#39;&#39;
</span></span></span><span style=display:flex><span><span style=color:#d88200>Now you can delete your runtime after you save your zipped vector db somewhere locally. To re-use your embeddings, follow the next steps 
</span></span></span><span style=display:flex><span><span style=color:#d88200>&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span><span style=color:#960050;background-color:#1e0010>!</span><span style=color:#111>unzip</span> <span style=color:#111>db</span><span style=color:#f92672>.</span><span style=color:#111>zip</span>
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> <span style=color:#111>os</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>os</span><span style=color:#f92672>.</span><span style=color:#111>environ</span><span style=color:#111>[</span><span style=color:#d88200>&#34;OPENAI_API_KEY&#34;</span><span style=color:#111>]</span> <span style=color:#f92672>=</span> <span style=color:#d88200>&#34;YOUR_KEY&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.vectorstores</span> <span style=color:#f92672>import</span> <span style=color:#111>Chroma</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.embeddings</span> <span style=color:#f92672>import</span> <span style=color:#111>OpenAIEmbeddings</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.chat_models</span> <span style=color:#f92672>import</span> <span style=color:#111>ChatOpenAI</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.chains</span> <span style=color:#f92672>import</span> <span style=color:#111>RetrievalQA</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>persist_directory</span> <span style=color:#f92672>=</span> <span style=color:#d88200>&#39;db&#39;</span>
</span></span><span style=display:flex><span><span style=color:#111>embedding</span> <span style=color:#f92672>=</span> <span style=color:#111>OpenAIEmbeddings</span><span style=color:#111>()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>vectordb2</span> <span style=color:#f92672>=</span> <span style=color:#111>Chroma</span><span style=color:#111>(</span><span style=color:#111>persist_directory</span><span style=color:#f92672>=</span><span style=color:#111>persist_directory</span><span style=color:#111>,</span> 
</span></span><span style=display:flex><span>                  <span style=color:#111>embedding_function</span><span style=color:#f92672>=</span><span style=color:#111>embedding</span><span style=color:#111>,</span>
</span></span><span style=display:flex><span>                   <span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>retriever</span> <span style=color:#f92672>=</span> <span style=color:#111>vectordb2</span><span style=color:#f92672>.</span><span style=color:#111>as_retriever</span><span style=color:#111>(</span><span style=color:#111>search_kwargs</span><span style=color:#f92672>=</span><span style=color:#111>{</span><span style=color:#d88200>&#34;k&#34;</span><span style=color:#111>:</span> <span style=color:#ae81ff>2</span><span style=color:#111>})</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set up the turbo LLM, for a more chat-like experience</span>
</span></span><span style=display:flex><span><span style=color:#111>turbo_llm</span> <span style=color:#f92672>=</span> <span style=color:#111>ChatOpenAI</span><span style=color:#111>(</span>
</span></span><span style=display:flex><span>    <span style=color:#111>temperature</span><span style=color:#f92672>=</span><span style=color:#ae81ff>0</span><span style=color:#111>,</span>
</span></span><span style=display:flex><span>    <span style=color:#111>model_name</span><span style=color:#f92672>=</span><span style=color:#d88200>&#39;gpt-3.5-turbo&#39;</span>
</span></span><span style=display:flex><span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#75715e># create the chain to answer questions </span>
</span></span><span style=display:flex><span><span style=color:#111>qa_chain</span> <span style=color:#f92672>=</span> <span style=color:#111>RetrievalQA</span><span style=color:#f92672>.</span><span style=color:#111>from_chain_type</span><span style=color:#111>(</span><span style=color:#111>llm</span><span style=color:#f92672>=</span><span style=color:#111>turbo_llm</span><span style=color:#111>,</span> 
</span></span><span style=display:flex><span>                                  <span style=color:#111>chain_type</span><span style=color:#f92672>=</span><span style=color:#d88200>&#34;stuff&#34;</span><span style=color:#111>,</span> 
</span></span><span style=display:flex><span>                                  <span style=color:#111>retriever</span><span style=color:#f92672>=</span><span style=color:#111>retriever</span><span style=color:#111>,</span> 
</span></span><span style=display:flex><span>                                  <span style=color:#111>return_source_documents</span><span style=color:#f92672>=</span><span style=color:#00a8c8>True</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#75715e>## Cite sources</span>
</span></span><span style=display:flex><span><span style=color:#00a8c8>def</span> <span style=color:#75af00>process_llm_response</span><span style=color:#111>(</span><span style=color:#111>llm_response</span><span style=color:#111>):</span>
</span></span><span style=display:flex><span>    <span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>llm_response</span><span style=color:#111>[</span><span style=color:#d88200>&#39;result&#39;</span><span style=color:#111>])</span>
</span></span><span style=display:flex><span>    <span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#d88200>&#39;</span><span style=color:#8045ff>\n\n</span><span style=color:#d88200>Sources:&#39;</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>    <span style=color:#00a8c8>for</span> <span style=color:#111>source</span> <span style=color:#f92672>in</span> <span style=color:#111>llm_response</span><span style=color:#111>[</span><span style=color:#d88200>&#34;source_documents&#34;</span><span style=color:#111>]:</span>
</span></span><span style=display:flex><span>        <span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>source</span><span style=color:#f92672>.</span><span style=color:#111>metadata</span><span style=color:#111>[</span><span style=color:#d88200>&#39;source&#39;</span><span style=color:#111>])</span>
</span></span><span style=display:flex><span><span style=color:#111>query</span> <span style=color:#f92672>=</span> <span style=color:#d88200>&#34;How much money did Pando raise?&#34;</span>
</span></span><span style=display:flex><span><span style=color:#111>llm_response</span> <span style=color:#f92672>=</span> <span style=color:#111>qa_chain</span><span style=color:#111>(</span><span style=color:#111>query</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span><span style=color:#111>process_llm_response</span><span style=color:#111>(</span><span style=color:#111>llm_response</span><span style=color:#111>)</span>                               
</span></span></code></pre></div><p>Now, to give it a more chat like experience for a user,</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.chains</span> <span style=color:#f92672>import</span> <span style=color:#111>RetrievalQA</span>
</span></span><span style=display:flex><span><span style=color:#111>qa_chain</span> <span style=color:#f92672>=</span> <span style=color:#111>RetrievalQA</span><span style=color:#f92672>.</span><span style=color:#111>from_chain_type</span><span style=color:#111>(</span><span style=color:#111>llm</span><span style=color:#f92672>=</span><span style=color:#111>OpenAI</span><span style=color:#111>(),</span> 
</span></span><span style=display:flex><span>                                  <span style=color:#111>chain_type</span><span style=color:#f92672>=</span><span style=color:#d88200>&#34;stuff&#34;</span><span style=color:#111>,</span> 
</span></span><span style=display:flex><span>                                  <span style=color:#111>retriever</span><span style=color:#f92672>=</span><span style=color:#111>retriever</span><span style=color:#111>,</span> 
</span></span><span style=display:flex><span>                                  <span style=color:#111>return_source_documents</span><span style=color:#f92672>=</span><span style=color:#00a8c8>True</span><span style=color:#111>)</span>
</span></span></code></pre></div><p>should be replaced as this does only basic retrieval, using something like ConversationalRetrievalChain suits it much better as here history is retained and chain is more conversational.</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.chains</span> <span style=color:#f92672>import</span> <span style=color:#111>ConversationalRetrievalChain</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>conv_chain</span> <span style=color:#f92672>=</span> <span style=color:#111>ConversationalRetrievalChain</span><span style=color:#f92672>.</span><span style=color:#111>from_llm</span><span style=color:#111>(</span><span style=color:#111>llm</span><span style=color:#f92672>=</span><span style=color:#111>OpenAI</span><span style=color:#111>(),</span> 
</span></span><span style=display:flex><span>                                                <span style=color:#111>retriever</span><span style=color:#f92672>=</span><span style=color:#111>retriever</span><span style=color:#111>,</span>
</span></span><span style=display:flex><span>                                                <span style=color:#111>return_source_documents</span><span style=color:#f92672>=</span> <span style=color:#00a8c8>True</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>query</span> <span style=color:#f92672>=</span> <span style=color:#d88200>&#34;How much money did Pando raise?&#34;</span>
</span></span><span style=display:flex><span><span style=color:#111>result</span> <span style=color:#f92672>=</span> <span style=color:#111>conv_chain</span><span style=color:#111>({</span><span style=color:#d88200>&#34;question&#34;</span><span style=color:#111>:</span> <span style=color:#111>query</span><span style=color:#111>,</span> <span style=color:#d88200>&#34;chat_history&#34;</span><span style=color:#111>:</span> <span style=color:#111>[]})</span>
</span></span><span style=display:flex><span><span style=color:#111>answer</span> <span style=color:#f92672>=</span> <span style=color:#111>result</span><span style=color:#111>[</span><span style=color:#d88200>&#34;answer&#34;</span><span style=color:#111>]</span>
</span></span><span style=display:flex><span><span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>answer</span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>followup_query</span> <span style=color:#f92672>=</span> <span style=color:#d88200>&#34;When was their last funding round?&#34;</span>
</span></span><span style=display:flex><span><span style=color:#111>result</span> <span style=color:#f92672>=</span> <span style=color:#111>conv_chain</span><span style=color:#111>({</span><span style=color:#d88200>&#34;question&#34;</span><span style=color:#111>:</span> <span style=color:#111>followup_query</span><span style=color:#111>,</span> <span style=color:#d88200>&#34;chat_history&#34;</span><span style=color:#111>:</span> <span style=color:#111>[(</span><span style=color:#111>query</span><span style=color:#111>,</span> <span style=color:#111>answer</span><span style=color:#111>)]})</span>
</span></span><span style=display:flex><span><span style=color:#111>followup_answer</span> <span style=color:#f92672>=</span> <span style=color:#111>result</span><span style=color:#111>[</span><span style=color:#d88200>&#34;answer&#34;</span><span style=color:#111>]</span>
</span></span><span style=display:flex><span><span style=color:#111>print</span><span style=color:#111>(</span><span style=color:#111>followup_answer</span><span style=color:#111>)</span>
</span></span></code></pre></div><p>But here too, we have to manually give chat history as input. To overcome this tedious process, LangChain provides some convenient built-in tools to automate chat history management in conversational chains:</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#d88200>&#39;&#39;&#39;
</span></span></span><span style=display:flex><span><span style=color:#d88200>using RunnableWithMessageHistory -  to automatically maintain chat history between calls
</span></span></span><span style=display:flex><span><span style=color:#d88200>&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain_core.runnables.history</span> <span style=color:#f92672>import</span> <span style=color:#111>RunnableWithMessageHistory</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>conv_chain_with_history</span> <span style=color:#f92672>=</span> <span style=color:#111>RunnableWithMessageHistory</span><span style=color:#111>(</span>
</span></span><span style=display:flex><span>    <span style=color:#111>conv_chain</span><span style=color:#111>,</span> 
</span></span><span style=display:flex><span>    <span style=color:#111>chat_message_history</span> <span style=color:#75715e># your chat history instance</span>
</span></span><span style=display:flex><span><span style=color:#111>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>result</span> <span style=color:#f92672>=</span> <span style=color:#111>conv_chain_with_history</span><span style=color:#111>({</span><span style=color:#d88200>&#34;input&#34;</span><span style=color:#111>:</span> <span style=color:#111>first_query</span><span style=color:#111>})</span>
</span></span><span style=display:flex><span><span style=color:#111>result</span> <span style=color:#f92672>=</span> <span style=color:#111>conv_chain_with_history</span><span style=color:#111>({</span><span style=color:#d88200>&#34;input&#34;</span><span style=color:#111>:</span> <span style=color:#111>followup_query</span><span style=color:#111>})</span> 
</span></span></code></pre></div><p>OR</p><div class=highlight><pre tabindex=0 style=color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#d88200>&#39;&#39;&#39;
</span></span></span><span style=display:flex><span><span style=color:#d88200>Using a ChatMessageHistory instance - The history instance stores chat turns and can
</span></span></span><span style=display:flex><span><span style=color:#d88200>be passed directly to the chain
</span></span></span><span style=display:flex><span><span style=color:#d88200>&#39;&#39;&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> <span style=color:#111>langchain.memory</span> <span style=color:#f92672>import</span> <span style=color:#111>ChatMessageHistory</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>history</span> <span style=color:#f92672>=</span> <span style=color:#111>ChatMessageHistory</span><span style=color:#111>()</span> 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>first_result</span> <span style=color:#f92672>=</span> <span style=color:#111>conv_chain</span><span style=color:#111>({</span><span style=color:#d88200>&#34;question&#34;</span><span style=color:#111>:</span> <span style=color:#111>first_query</span><span style=color:#111>,</span> <span style=color:#d88200>&#34;chat_history&#34;</span><span style=color:#111>:</span> <span style=color:#111>history</span><span style=color:#f92672>.</span><span style=color:#111>messages</span><span style=color:#111>})</span>
</span></span><span style=display:flex><span><span style=color:#111>history</span><span style=color:#f92672>.</span><span style=color:#111>add_conversation_turn</span><span style=color:#111>(</span><span style=color:#111>first_query</span><span style=color:#111>,</span> <span style=color:#111>first_result</span><span style=color:#111>[</span><span style=color:#d88200>&#34;answer&#34;</span><span style=color:#111>])</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#111>second_result</span> <span style=color:#f92672>=</span> <span style=color:#111>conv_chain</span><span style=color:#111>({</span><span style=color:#d88200>&#34;question&#34;</span><span style=color:#111>:</span> <span style=color:#111>second_query</span><span style=color:#111>,</span> <span style=color:#d88200>&#34;chat_history&#34;</span><span style=color:#111>:</span> <span style=color:#111>history</span><span style=color:#f92672>.</span><span style=color:#111>messages</span><span style=color:#111>})</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Further turns...</span>
</span></span></code></pre></div><p>Now, I want to use RunnableWithMessageHistory, but I am currently not depending on any external storage for my message histroy. To solve this, I am going to use an in-memory ChatMessageHistory instance and pass it to RunnableWithMessageHistory</p></div></div></div></div><div class=container><div class="row justify-content-between"><div class=col-sm-4><p class=footer>Ritesh Panditi Â© 2024</p></div><div class="col-sm-6 d-flex flex-row-reverse"><a class="footer-social px-2" href=# target=_blank><i class="fab fa-twitter"></i></a>
<a class="footer-social px-2" href=# target=_blank><i class="fab fa-github"></i></a>
<a class="footer-social px-2" href=# target=_blank><i class="fab fa-medium-m"></i></a>
<a class="footer-social px-2" href=# target=_blank><i class="fab fa-linkedin-in"></i></a></div></div></div><script src=/Digital-garden/js/bootstrap.min.js></script>
<script type=text/javascript src=/Digital-garden/js/jquery.min.js></script>
<script src=/Digital-garden/js/isotope.pkgd.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js integrity=sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D crossorigin=anonymous async></script>
<script src=/Digital-garden/js/dark.js></script>
<script>var savedTheme=localStorage.getItem("dark-mode-storage")||"light";setTheme(savedTheme)</script><script src=/Digital-garden/js/isotope.js></script>
<script src=/Digital-garden/js/mermaid.min.js></script>
<script>mermaid.initialize({startOnLoad:!0,securityLevel:"loose"})</script><script src=/Digital-garden/js/tag_handler.js></script></body></html>